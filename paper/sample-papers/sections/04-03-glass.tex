%\subsection{glass}

%Results for \textit{glass} dataset are presented in \cref{fig:glass} and \cref{tab:glass}. The
%dataset has 6 classes and it is unbalanced \cref{fig:glass:dist-class}. The performance of
%algorithms is now worse with baseline error ranging from 25\% for RF to 93\% for QDA, see
%\cref{fig:glass:baseline-error}. The difference between the effectiveness of different conformal
%classifiers is also clearly visible on the plots.
%
%We can notice that \textit{margin} is clearly preferred in cases when DT, KNN and QDA are used as baseline classifiers, see \cref{fig:glass:oneC-SVM-DT}, \cref{fig:glass:avgC-SVM-DT}, \cref{fig:glass:oneC-KNN-Ada}, \cref{fig:glass:avgC-KNN-Ada}, \cref{fig:glass:oneC-RF-QDA},
%and \cref{fig:glass:avgC-RF-QDA} and the results in \cref{tab:glass}. For the rest of the
%classifiers the previous observed pattern holds: \textit{margin} is better for $oneC$ and
%\textit{inverse probability} is better for $avgC$. In all these cases, \textit{ip\_m} allows to improve $oneC$ obtained by the \textit{inverse probability} function and improves both \textit{inverse probability} and \textit{margin} in terms of $avgC$. In case of MPR classifier, we can observe improvement in terms of both metrics when \textit{ip\_m} is used. It means that this metric is the best for conformal predictor based on MPR, see \cref{fig:glass:oneC-GNB-MPR}
%and \cref{fig:glass:avgC-GNB-MPR}.

\include{paper/sample-papers/sections/3-glass-data/plots}

\include{paper/sample-papers/sections/3-glass-data/table_threshold}

%\include{paper/sample-papers/sections/3-glass-data/table}